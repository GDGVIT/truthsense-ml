{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249b5d9a",
   "metadata": {},
   "source": [
    "# Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25780097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas librosa torch groq load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771b07d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tiktoken in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: pytubefix in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (9.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: aiohttp>=3.12.13 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from pytubefix) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from aiohttp>=3.12.13->pytubefix) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from aiohttp>=3.12.13->pytubefix) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from aiohttp>=3.12.13->pytubefix) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from aiohttp>=3.12.13->pytubefix) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from aiohttp>=3.12.13->pytubefix) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from aiohttp>=3.12.13->pytubefix) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from aiohttp>=3.12.13->pytubefix) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from aiohttp>=3.12.13->pytubefix) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp>=3.12.13->pytubefix) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.12.13->pytubefix) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken pytubefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bfa84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import librosa\n",
    "from groq import Groq\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "# Load environment file\n",
    "from load_dotenv import load_dotenv\n",
    "print(load_dotenv('../../.env.local'))\n",
    "\n",
    "assert os.environ.get('GROQ_API_KEY'), \"Groq API key not found in .env file, please set the key before starting this notebook\"\n",
    "\n",
    "# Global variables\n",
    "client = Groq()\n",
    "\n",
    "try:\n",
    "    cmu_dict = cmudict.dict()\n",
    "except:\n",
    "    import nltk\n",
    "    nltk.download('cmudict')\n",
    "    cmu_dict = cmudict.dict()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c16201",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Features extracted:\n",
    "\t•\tZCR\n",
    "\t•\tPitch\n",
    "\t•\tRMS\n",
    "\t•\tMFCC\n",
    "\t•\tDeltaMFCC\n",
    "\t•\tSpeakingRate\n",
    "\t•\tPauseCount\n",
    "\t•\tPauseDuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "958711f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path, client=client):\n",
    "    with open(audio_path, \"rb\") as file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "        file=(audio_path, file.read()),\n",
    "        model=\"distil-whisper-large-v3-en\",\n",
    "        response_format=\"verbose_json\",\n",
    "        timestamp_granularities=['word', 'segment']\n",
    "        )\n",
    "\n",
    "    return transcription\n",
    "\n",
    "\n",
    "def get_word_syllable_count(word):\n",
    "    word = word.lower().strip(\".,?!;:\")\n",
    "    if word in cmu_dict:\n",
    "        return len([p for p in cmu_dict[word][0] if p[-1].isdigit()])\n",
    "    return max(1, len(re.findall(r'[aeiouy]+', word)))\n",
    "\n",
    "\n",
    "def estimate_syllable_rate(transcript, duration_sec):\n",
    "    words = transcript.split()\n",
    "    total_syllables = sum(get_word_syllable_count(word) for word in words)\n",
    "    return total_syllables / duration_sec if duration_sec > 0 else 0\n",
    "\n",
    "\n",
    "def extract_features_from_wave(data, sr, prefix: str = \"\"):\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(data))\n",
    "\n",
    "    pitch = librosa.yin(data, fmin=librosa.note_to_hz(\"C2\"), fmax=librosa.note_to_hz(\"C7\"), sr=sr)\n",
    "    pitch = np.nan_to_num(pitch)\n",
    "    pitch_mean = np.mean(pitch)\n",
    "    pitch_std = np.std(pitch)\n",
    "    pitch_var = np.var(pitch)\n",
    "\n",
    "    rms = librosa.feature.rms(y=data)[0]\n",
    "    rms_mean = np.mean(rms)\n",
    "    rms_std = np.std(rms)\n",
    "    rms_var = np.var(rms)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_mean = np.mean(mfcc)\n",
    "    delta_mean = np.mean(delta)\n",
    "\n",
    "    return {\n",
    "        \"zcr\": zcr,\n",
    "        \"pitch_mean\": pitch_mean,\n",
    "        \"pitch_std\": pitch_std,\n",
    "        \"pitch_var\": pitch_var,\n",
    "        \"rms_mean\": rms_mean,\n",
    "        \"rms_std\": rms_std,\n",
    "        \"rms_var\": rms_var,\n",
    "        \"mfcc_mean\": mfcc_mean,\n",
    "        \"delta_mean\": delta_mean\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_features(audio_path, baseline_duration=10.0):\n",
    "    data, sr = librosa.load(audio_path)\n",
    "\n",
    "    assert len(data) != 0, \"Your audio file appears to contain no content. Please input a valid file\"\n",
    "    assert baseline_duration != 0, \"Baseline cannot be 0!\"\n",
    "    assert baseline_duration < len(data) / sr, \"Baseline cannot be greater than the length of the audio file input\"\n",
    "    \n",
    "    # Baseline from first few seconds\n",
    "    baseline_data = data[:min(len(data), int(sr * baseline_duration))]\n",
    "    baseline_feats = extract_features_from_wave(baseline_data, sr)\n",
    "    full_feats = extract_features_from_wave(data, sr)\n",
    "\n",
    "    relative_feats = {}\n",
    "    for key in full_feats:\n",
    "        base = baseline_feats.get(key, 0.0)\n",
    "        full = full_feats[key]\n",
    "        relative_feats[f'{key}_delta'] = full - base\n",
    "        relative_feats[f'{key}_ratio'] = full / base if base != 0 else 0\n",
    "\n",
    "    # Transcription and Speaking Rates\n",
    "    transcription_json = transcribe_audio(audio_path)\n",
    "    duration_sec = transcription_json.duration # type: ignore\n",
    "    baseline_duration = max(10.0, duration_sec * 0.05)\n",
    "    print(baseline_duration)\n",
    "\n",
    "    assert duration_sec != 0, \"File duration appears to be 0 after transcription?\"\n",
    "    \n",
    "    # Full data speaking rate\n",
    "    transcript = transcription_json.text\n",
    "    word_count = len(transcript.split())\n",
    "    speaking_rate = word_count / duration_sec\n",
    "    syllables_rate = estimate_syllable_rate(transcript, duration_sec)\n",
    "    \n",
    "    # Baseline speaking rate\n",
    "    baseline_transcript = [word_segment['word'] for word_segment in transcription_json.words if word_segment['start'] <= baseline_duration]  # type: ignore\n",
    "    baseline_word_count = len(baseline_transcript)\n",
    "    baseline_transcript = \" \".join(baseline_transcript)\n",
    "    baseline_speaking_rate = baseline_word_count / baseline_duration\n",
    "    baseline_syllables_rate = estimate_syllable_rate(baseline_transcript, baseline_duration)\n",
    "    \n",
    "    # Pause detection\n",
    "    intervals = librosa.effects.split(data, top_db=30)\n",
    "    pauses = [(intervals[i][0] - intervals[i - 1][1]) / sr\n",
    "              for i in range(1, len(intervals))\n",
    "              if (intervals[i][0] - intervals[i - 1][1]) / sr > 1.0]\n",
    "    \n",
    "    long_pause_count = len(pauses)\n",
    "    long_pause_total = sum(pauses)\n",
    "\n",
    "    return {\n",
    "        \"transcript\": transcript,\n",
    "        \"duration\": duration_sec,\n",
    "        \"baseline_duration\": baseline_duration,\n",
    "        \"speaking_rate\": speaking_rate,\n",
    "        \"syllables_rate\": syllables_rate,\n",
    "        \"baseline_speaking_rate\": baseline_speaking_rate,\n",
    "        \"baseline_syllables_rate\": baseline_syllables_rate,\n",
    "        \"long_pause_count\": long_pause_count,\n",
    "        \"long_pause_duration\": long_pause_total,\n",
    "        **full_feats,\n",
    "        **{f'baseline_{k}': v for k, v in baseline_feats.items()},\n",
    "        **relative_feats,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05c6d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\AppData\\Local\\Temp\\ipykernel_2640\\1006254953.py:59: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sr = librosa.load(audio_path)\n",
      "c:\\Users\\Utkarsh\\OneDrive\\Documents\\GitHub\\truthsense-ml\\.venv\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "features = extract_features('../../samples/unconfident.m4a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc49174",
   "metadata": {},
   "source": [
    "# Send to GPT for feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751d8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(features):\n",
    "    prompt = f\"\"\"\n",
    "You are a professional voice coach and delivery analyst tasked with evaluating a speaker's performance based on a variety of acoustic and prosodic features. Below is an in-depth description of the speech signal, including baseline characteristics, absolute values, and relative shifts.\n",
    "\n",
    "## NOTE:\n",
    "- The **first 10 seconds** of the speech are used to define the speaker's personal baseline.\n",
    "- All relative metrics (e.g., deltas, ratios) are calculated with respect to this baseline.\n",
    "- Your feedback should interpret the *changes* from baseline — not just absolute values — as indicators of intentional modulation or stress, not necessarily flaws.\n",
    "\n",
    "## TRANSCRIPT\n",
    "<transcript> \n",
    "{features['transcript']} \n",
    "</transcript>\n",
    "\n",
    "## BASELINE METRICS\n",
    "- Speaking rate: {features['baseline_speaking_rate']:.2f} words/sec\n",
    "- Speaking rate: {features['baseline_syllables_rate']:.2f} syllables/sec\n",
    "- Pitch (Mean; Standard deviation; Variation): {features['baseline_pitch_mean']:.2f}; {features['baseline_pitch_std']:.2f}; {features['baseline_pitch_var']:.2f}\n",
    "- RMS Energy (Mean; Standard deviation; Variation): {features['baseline_rms_mean']:.2f}; {features['baseline_rms_std']:.2f}; {features['baseline_rms_var']:.2f}\n",
    "- ZCR: {features['baseline_zcr']:.2f}\n",
    "- MFCC and Delta MFCC Mean: {features['baseline_mfcc_mean']:.2f}; {features['baseline_delta_mean']:.2f}\n",
    "\n",
    "## RAW METRICS (FOR THE WHOLE SPEECH)\n",
    "- Speaking Rate: {features['speaking_rate']:.2f} words/sec\n",
    "- Speaking rate: {features['baseline_syllables_rate']:.2f} syllables/sec\n",
    "- Long Pauses: {features['long_pause_count']} (>1s)\n",
    "- Total Long Pause Duration: {features['long_pause_duration']:.2f} sec\n",
    "- Pitch (Mean; Standard deviation; Variation): {features['pitch_mean']:.2f}; {features['pitch_std']:.2f}; {features['pitch_var']:.2f}\n",
    "- RMS Energy (Mean; Standard deviation; Variation): {features['rms_mean']:.2f}; {features['rms_std']:.2f}; {features['rms_var']:.2f}\n",
    "- ZCR: {features['zcr']:.2f}\n",
    "- MFCC and Delta MFCC Mean: {features['mfcc_mean']:.2f}; {features['delta_mean']:.2f}\n",
    "\n",
    "## RELATIVE CHANGES FROM BASELINE\n",
    "- Pitch variation change (std): {features['pitch_std_delta']:+.2f}\n",
    "- RMS Energy mean change: {features['rms_mean_delta']:+.2f}\n",
    "- Speaking rate ratio: {features['speaking_rate'] / features['baseline_speaking_rate']}\n",
    "- Interpretation Tip:\n",
    "    - A Pitch variation change > 0 may suggest more modulation than usual; < 0 may suggest flattening.\n",
    "    - RMS mean delta > 0 = more vocal energy than the beginning few seconds.\n",
    "    - Speaking rate ratio < 1 = speaker slowed down as compared to the start of their speech.\n",
    "    NOTE: This tip should not be used as an absolute, a speaking rate slowing could mean anxiety as well, infer that from the script\n",
    "\n",
    "## INSTRUCTION\n",
    "\n",
    "Now, based on this input, write a narrative-style feedback giving clear, constructive, and context-aware feedback. \n",
    "\n",
    "DO NOT judge the speaker based on universal norms; instead, use their own baseline as reference to detect signs of:\n",
    "- Increased or decreased vocal control,\n",
    "- Confidence shifts,\n",
    "- Monotony vs. modulation,\n",
    "- Hesitation or fluency issues.\n",
    "\n",
    "You are a closed source model. So you are expected not to reference any specific acoustic features and their values in your feedback.\n",
    "\n",
    "Split your feedback in 3 parts: What they did correctly, what they could improve on, and rate their confidence and fluency levels based on the relative metrics.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_feedback(features):\n",
    "    prompt = get_prompt(features)\n",
    "\n",
    "    client = Groq()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        max_completion_tokens=32768,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31321419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7928aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "787"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = tiktoken.get_encoding('gpt2')\n",
    "len(encoder.encode(get_prompt(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211bdbf",
   "metadata": {},
   "source": [
    "# Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0365e68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\AppData\\Local\\Temp\\ipykernel_2640\\1006254953.py:59: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sr = librosa.load(audio_path)\n",
      "c:\\Users\\Utkarsh\\OneDrive\\Documents\\GitHub\\truthsense-ml\\.venv\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "# An unconfident speech\n",
    "path = \"../../samples/unconfident.m4a\"\n",
    "features = extract_features(path)\n",
    "feedback = generate_feedback(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e792308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Part 1: Strengths\n",
       "\n",
       "The speaker demonstrates a notable ability to modulate their voice, suggesting an attempt to convey emotions and emphasize certain points. This modulation is a positive aspect, as it adds variety to the speech and helps maintain the listener's engagement. The speaker's overall pace, while slightly adjusted from their baseline, still allows for clear understanding of the message. It's commendable that despite admitting to a fear of public speaking, the speaker pushes through and delivers their message, showing resilience.\n",
       "\n",
       "## Part 2: Areas for Improvement\n",
       "\n",
       "There are moments where the speaker seems to hesitate, indicated by repetitive filler words and slight pauses. These hesitations could be interpreted as signs of nervousness or lack of confidence in what is being said. Working on reducing these filler words and pauses could help improve the overall fluency of the speech. Additionally, there are instances where the speaker's voice could benefit from more consistent energy, as there are subtle shifts that might suggest moments of heightened anxiety or doubt. Practicing speech in a comfortable environment could help in achieving a more balanced delivery.\n",
       "\n",
       "## Part 3: Confidence and Fluency Assessment\n",
       "\n",
       "Based on the relative changes from the speaker's baseline, it appears that there is a moderate level of confidence, albeit with noticeable dips. The speaker's attempt to modulate their voice suggests an effort to engage the audience, which is a confident trait. However, the presence of filler words and slight pauses indicates some hesitation, which might suggest that the speaker is not entirely comfortable with public speaking, as they themselves admitted. The fluency is somewhat affected by these hesitations but not severely impaired, allowing the core message to be understood. On a scale of 1 to 10, with 10 being the highest, I would rate the speaker's confidence a 6 and their fluency a 7. With practice and experience, these scores could potentially increase as the speaker becomes more comfortable with expressing themselves publicly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Markdown(feedback.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a8ec9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\AppData\\Local\\Temp\\ipykernel_2640\\1006254953.py:59: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sr = librosa.load(audio_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "# A confident speech\n",
    "path = \"../../samples/confident.m4a\"\n",
    "features = extract_features(path)\n",
    "feedback = generate_feedback(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41201a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcript': \" Hi, my name is Adkarsh Malaya. I'm a student and right now what I'm trying to do is I'm trying to get a model and I'm trying to use it to transcribe some filler words. I am very scared. I don't know what will happen and I really really hope this works.\",\n",
       " 'duration': 15.72,\n",
       " 'baseline_duration': 10.0,\n",
       " 'speaking_rate': 3.3078880407124682,\n",
       " 'syllables_rate': 4.134860050890585,\n",
       " 'baseline_speaking_rate': 3.3,\n",
       " 'baseline_syllables_rate': 4.1,\n",
       " 'long_pause_count': 0,\n",
       " 'long_pause_duration': 0,\n",
       " 'zcr': 0.08035611403023599,\n",
       " 'pitch_mean': 287.1815062705668,\n",
       " 'pitch_std': 466.33901796330355,\n",
       " 'pitch_var': 217472.07967497836,\n",
       " 'rms_mean': 0.0131712835,\n",
       " 'rms_std': 0.010488089,\n",
       " 'rms_var': 0.00011000002,\n",
       " 'mfcc_mean': -24.901373,\n",
       " 'delta_mean': 0.01626812,\n",
       " 'baseline_zcr': 0.07430711644431555,\n",
       " 'baseline_pitch_mean': 272.55173088127896,\n",
       " 'baseline_pitch_std': 445.4344329724631,\n",
       " 'baseline_pitch_var': 198411.83407749975,\n",
       " 'baseline_rms_mean': 0.013894684,\n",
       " 'baseline_rms_std': 0.01011108,\n",
       " 'baseline_rms_var': 0.000102233935,\n",
       " 'baseline_mfcc_mean': -23.967363,\n",
       " 'baseline_delta_mean': 0.08120845,\n",
       " 'zcr_delta': 0.006048997585920438,\n",
       " 'zcr_ratio': 1.0814053602854237,\n",
       " 'pitch_mean_delta': 14.629775389287829,\n",
       " 'pitch_mean_ratio': 1.0536770591842635,\n",
       " 'pitch_std_delta': 20.90458499084042,\n",
       " 'pitch_std_ratio': 1.0469307791302536,\n",
       " 'pitch_var_delta': 19060.245597478613,\n",
       " 'pitch_var_ratio': 1.09606405629028,\n",
       " 'rms_mean_delta': -0.00072340015,\n",
       " 'rms_mean_ratio': 0.9479369,\n",
       " 'rms_std_delta': 0.00037700962,\n",
       " 'rms_std_ratio': 1.0372868,\n",
       " 'rms_var_delta': 7.766088e-06,\n",
       " 'rms_var_ratio': 1.0759639,\n",
       " 'mfcc_mean_delta': -0.93400955,\n",
       " 'mfcc_mean_ratio': 1.0389701,\n",
       " 'delta_mean_delta': -0.06494033,\n",
       " 'delta_mean_ratio': 0.20032544}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7ec295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Part 1: Strengths\n",
       "The speaker demonstrates a strong ability to maintain a consistent pace throughout their speech, showing minimal deviation from their initial speaking rate. This suggests a good level of comfort with the topic and an ability to articulate their thoughts without significant hesitation. Additionally, the speaker's vocal energy remains relatively stable, indicating a consistent level of engagement and enthusiasm for the subject matter. Overall, the speaker's baseline characteristics provide a solid foundation for effective communication.\n",
       "\n",
       "## Part 2: Areas for Improvement\n",
       "There are some subtle indications that the speaker may be experiencing a slight increase in emotional arousal or modulation during certain parts of the speech. This could be interpreted as a natural response to the topic, but it may also suggest that the speaker is not entirely at ease with the material or is experiencing some level of anxiety. Furthermore, while the speaker's pace remains relatively consistent, there are no significant pauses or breaks to allow for emphasis or dramatic effect, which could make the speech feel somewhat monotone or flat at times. By introducing more deliberate pauses or variations in pace, the speaker could add more nuance and interest to their delivery.\n",
       "\n",
       "## Part 3: Confidence and Fluency Assessment\n",
       "Based on the relative changes from the speaker's baseline, it appears that their confidence levels may be slightly impacted by the topic or the situation. The subtle increase in modulation suggests that the speaker may be experiencing some level of emotional arousal, which could be related to anxiety or nervousness. However, this does not seem to significantly impair their fluency, as they are still able to articulate their thoughts and maintain a consistent pace. I would rate the speaker's confidence level as moderately affected, with a score of 6 out of 10. Their fluency level, on the other hand, remains relatively high, with a score of 8 out of 10, indicating that they are able to communicate their ideas clearly and effectively, despite some minor hints of hesitation or emotional influence. Overall, the speaker demonstrates a good level of fluency and some areas for improvement in terms of confidence and emotional control."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipd.Markdown(feedback.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f54ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the audio from Tim Urban's TED talk and using that to assess the model\n",
    "from pytubefix import YouTube\n",
    "\n",
    "if not os.path.exists(\"../../samples/tim-urban.m4a\"):\n",
    "    yt = YouTube('https://www.youtube.com/watch?v=arj7oStGLkU')\n",
    "    yt.streams.get_audio_only().download('../../samples', 'tim-urban.m4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40662727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\AppData\\Local\\Temp\\ipykernel_2640\\1006254953.py:59: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sr = librosa.load(audio_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.1872517\n"
     ]
    }
   ],
   "source": [
    "tim_urban_path = \"../../samples/tim-urban.m4a\"\n",
    "tim_urban_features = extract_features(tim_urban_path)\n",
    "tim_urban_feedback = generate_feedback(tim_urban_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc3740e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3478"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.encode(get_prompt(tim_urban_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddedf701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcript': \" Reviewer.pxs. So in college, I was a government major, which means I had to write a lot of papers. Now, when a normal student writes a paper, they might spread the work out a little like this. So, you know, you get started maybe a little slowly, but you get enough done in the first week that with some heavier days later on, everything gets done and things stay civil. And I would want to do that like that. That would be the plan. I would have it all ready to go, but then actually the paper would come along, and then I would kind of do this. And that would happen every single paper. But then came my 90-page senior thesis, a paper you're supposed to spend a year on. I knew for a paper like that, my normal workflow was not an option, it was way too big a project. So I planned things out and I decided I kind of had to go something like this. This is how the year would go. So I'd start off light, and I'd bump it up in the middle months, and then at the end, I would kick it up into high gear, just like a little staircase. How hard can it be to just walk up the stairs? No big deal, right? But then the funniest thing happened. Those first few months, They came and went, and I couldn't quite do stuff. So we had an awesome new revised plan. And then ... But then those middle months actually went by, and I didn't really write words. And so we were here. And then two months turned into one month, which turned into two weeks. And one day I woke up with three days until the deadline, still not having written a word. And so I did the only thing I could. I wrote 90 pages over 72 hours, pulling not one but two all-nighters. Humans are not supposed to pull two all-nighters. Sprinted across campus, dove in slow motion, and got it in just at the deadline. I thought that was the end of everything. But a week later, I get a call. It's the school. And they say, is this Tim Urban? And I say, yeah. And they say, we need to talk about your thesis. And I say, OK. And they say, it's the best one we've ever seen. That did not happen. It was a very, very bad thesis. I just wanted to enjoy that one moment when all of you thought, this guy is amazing. No, no, it was very, very bad. Anyway, today I'm a writer, blogger, guy. I write the blog Wait But Why. And a couple of years ago, I decided to write about procrastination. My behaviors always perplexed the non-procrastinators around me, and I wanted to explain to the non-procrastinators of the world what goes on in the heads of procrastinators and why we are the way we are. Now, I had a hypothesis that the brains of procrastinators were actually different than the brains of other people. And to test this, I found an MRI lab that actually let me scan both my brain and the brain of a proven non so I could compare them And I actually brought them here to show you today and I want you to take a look carefully to see if you can notice a difference And I know that if you not a trained brain expert it's not that obvious, but just take a look, okay? So here's the brain of a non-procrastinator. Now, here's my brain. There is a difference. Both brains have a rational decision maker in them, but the procrastinator's brain also has an instant gratification monkey. Now, what does this mean for the procrastinator? Well, it means everything's fine until this happens. So the rational decision maker will make the rational decision to do something productive, but the monkey doesn't like that plan. So he actually takes the wheel and he says, actually, let's read the entire Wikipedia page of the Nancy Kerrigan-Tanya Harding scandal, because I just remembered that that happened. Then ... Then we're going to go over to the fridge, we're going to see if there's anything new in there since 10 minutes ago. After that, we're going to go on a YouTube spiral that starts with videos of Richard Feynman talking about magnets and ends much, much later with us watching interviews with Justin Bieber's mom. All of that's going to take a while, so we're not going to really have room on the schedule for any work today. Sorry. Now, what is going on here? The instant gratification monkey does not seem like a guy you want behind the wheel. He lives entirely in the present moment, he has no memory of the past, no knowledge of the future, and he only cares about two things, easy and fun. Now, in the animal world, that works fine. If you're a dog, and you spend your whole life doing nothing other than easy and fun things, you're a huge success. And to the monkey, humans are just another animal species. It has to keep well-slept, well-fed and propagating into the next generation. Which in tribal times might have worked OK. But if you haven't noticed, now we're not in tribal times. We're in an advanced civilization, and the monkey does not know what that is. Which is why we have another guy in our brain, the rational decision-maker, who gives us the ability to do things no other animal can do. We can visualize the future, we can see the big picture, we can make long-term plans. And he wants to take all of that into account, and he wants to just have us do whatever makes sense to be doing right now. Now, sometimes it makes sense to be doing things that are easy and fun, like when you're having dinner, or going to bed, enjoying well-earned leisure time. That's why there's an overlap. Sometimes they agree. But other times, it makes much more sense to be doing things that are harder and less pleasant for the sake of the big picture, and that's when we have a conflict. And for the procrastinator, that conflict tends to end a certain way every time, leaving him spending a lot of time in this orange zone, an easy and fun place that's entirely out of the make-sense circle. I call it the dark playground. Now, the dark playground is a place that all of you procrastinators out there know very well. It's where leisure activities happen at times when leisure activities are not supposed to be happening. The fun you have in the dark playground isn actually fun because it completely unearned and the air is filled with guilt dread anxiety self all those good procrastinator feelings And the question is in this situation with the monkey behind the wheel how does the procrastinator ever get himself over here to this blue zone, a less pleasant place, but where really important things happen? Well, it turns out that the procrastinator has a guardian angel, someone who's always looking down on him watching over him in his darkest moments, someone called the Panic Monster. Now, the Panic Monster is dormant most of the time, but he suddenly wakes up. Any time a deadline gets too close or there's danger of public embarrassment, a career disaster or some other scary consequence, and importantly, he's the only thing that the monkey is terrified of. Now, he became very relevant in my life pretty recently because the people of TED reached out to me about six months ago and invited me to do a TED Talk. Now, of course, I said, yes, it's always been a dream of mine to have done a TED Talk in the past. But in the middle of all this excitement, the rational decision-maker seemed to have something else in his mind. He was saying, are we clear on what we just accepted? Do we get what's going to be now happening one day in the future? We need to sit down and work on this right now. And the monkey said, totally agree, but also let's just open Google Earth and let's zoom into the bottom of India, like 200 feet above the ground, and we're going to scroll up for two and a half hours until we get to the top of the country so we can get a better feel for India. So that's what we did that day. As six months turned into four, and then two, and then one, the people of TED decided to release the speakers. And I opened up the website, and there was my face staring right back at me, and guess who woke up? So the panic monster starts losing his mind, and a few seconds later, the whole system's in mayhem. And the monkey, who, remember, he's terrified of the panic monster. Boom, he's up the tree. And finally, finally, the rational decision-maker can take the wheel, and I can start working on the talk. Now, the panic monster explains all kinds of pretty insane, procrastinated behavior, like how someone like me could spend two weeks unable to start the opening sentence of a paper and then miraculously find the unbelievable work ethic to stay up all night and write eight pages. And this entire situation with the three characters, this is the procrastinator's system. It's not pretty, but in the end, it works. And this is what I decided to write about on the blog just a couple years ago. Now, when I did, I was amazed by the response. Literally thousands of emails came in from all different kinds of people, from all over the world, doing all different kinds of things. These were people who were nurses and bankers and painters and engineers and lots and lots of PhD students. And they were all writing saying the same thing I have this problem too But what struck me was the contrast between the light tone of the post and the heaviness of these emails These people were writing with intense frustration about what procrastination had done to their lives, about what this monkey had done to them. And I thought about this, and I said, if the procrastinator system works, then what's going on? Why are all these people in such a dark place? It turns out that there's two kinds of procrastination. Everything I've talked about today, the examples I've given, they all have deadlines. And when there's deadlines, the effects of procrastination are contained to the short term because the panic monster gets involved. But there's a second kind of procrastination that happens in situations when there is no deadline. So if you want to have a career where you want to be a self-starter, something in the arts, something entrepreneurial, there's no deadlines on those things at first, because nothing's happening at first, until you've gone out and done the hard work to get some momentum, to get things going. There's also all kinds of important things outside of your career that don't involve any deadlines, like seeing your family or exercising and taking care of your health, working on your relationship or getting out of a relationship that isn't working. Now, if the procrastinator's only mechanism of doing these hard things is the panic monster, that's a problem, because in all of these non-deadline situations, the panic monster doesn't show up, he has nothing to wake up for, The effects of procrastination, they're not contained, they just extend outward forever. And it's this long-term kind of procrastination that's much less visible and much less talked about than the funnier short-term deadline-based kind. It's usually suffered quietly and privately, and it can be the source of a huge amount of long-term unhappiness and regrets. And I thought, you know, that's why these people are emailing, and that's why they're in such a bad place. It's not that they're cramming for some project. It's that long-term procrastination has made them feel like a spectator, at times, in their own lives. The frustration was not that they couldn't achieve their dreams, it's that they weren't even able to start chasing them. So I read these emails and I had a little bit of an epiphany that I don't think non-procrastinators exist. That's right, I think all of you are procrastinators. Now, you might not all be a mess, like some of us. And some of you may have a healthy relationship with deadlines. But remember, the monkey's sneakiest trick is when the deadlines aren't there. Now, I want to show you one last thing. I call this a life calendar. That's one box for every week of a 90-year life. That's not that many boxes, especially since we've already used a bunch of those. So I think we need to all take a long, hard look at that calendar. And we need to think about what we're really procrastinating on, because everyone is procrastinating on something in life. We need to stay aware of the instant gratification monkey. That's a job for all of us. And because there's not that many boxes on there, it's a job that should probably start today. Well, maybe not today, but ... You know, sometime soon. Thank you.\",\n",
       " 'duration': 843.7450339999999,\n",
       " 'baseline_duration': 42.1872517,\n",
       " 'speaking_rate': 2.661941593128239,\n",
       " 'syllables_rate': 3.7167626162289213,\n",
       " 'baseline_speaking_rate': 2.2281612622800933,\n",
       " 'baseline_syllables_rate': 2.7733496562422437,\n",
       " 'long_pause_count': 28,\n",
       " 'long_pause_duration': 39.96154195011337,\n",
       " 'zcr': 0.12431602464380555,\n",
       " 'pitch_mean': 297.7152699555939,\n",
       " 'pitch_std': 337.9058853964825,\n",
       " 'pitch_var': 114180.38738558079,\n",
       " 'rms_mean': 0.070083246,\n",
       " 'rms_std': 0.061486296,\n",
       " 'rms_var': 0.0037805648,\n",
       " 'mfcc_mean': -14.877528,\n",
       " 'delta_mean': 0.00010704117,\n",
       " 'baseline_zcr': 0.0985455789588167,\n",
       " 'baseline_pitch_mean': 344.77829722568737,\n",
       " 'baseline_pitch_std': 568.1480977328476,\n",
       " 'baseline_pitch_var': 322792.26095745334,\n",
       " 'baseline_rms_mean': 0.06299822,\n",
       " 'baseline_rms_std': 0.048998803,\n",
       " 'baseline_rms_var': 0.0024008828,\n",
       " 'baseline_mfcc_mean': -3.0564888,\n",
       " 'baseline_delta_mean': 0.0722437,\n",
       " 'zcr_delta': 0.025770445684988846,\n",
       " 'zcr_ratio': 1.261507882517577,\n",
       " 'pitch_mean_delta': -47.06302727009347,\n",
       " 'pitch_mean_ratio': 0.8634977095461243,\n",
       " 'pitch_std_delta': -230.24221233636513,\n",
       " 'pitch_std_ratio': 0.594749655494528,\n",
       " 'pitch_var_delta': -208611.87357187254,\n",
       " 'pitch_var_ratio': 0.35372715271085975,\n",
       " 'rms_mean_delta': 0.0070850253,\n",
       " 'rms_mean_ratio': 1.112464,\n",
       " 'rms_std_delta': 0.012487493,\n",
       " 'rms_std_ratio': 1.254853,\n",
       " 'rms_var_delta': 0.001379682,\n",
       " 'rms_var_ratio': 1.5746561,\n",
       " 'mfcc_mean_delta': -11.821039,\n",
       " 'mfcc_mean_ratio': 4.8675227,\n",
       " 'delta_mean_delta': -0.072136655,\n",
       " 'delta_mean_ratio': 0.0014816679}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tim_urban_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65042b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Part 1: Strengths\n",
       "\n",
       "The speaker demonstrates a strong ability to engage with their audience through their narrative, showcasing a clear and relatable storytelling style. Their use of personal anecdotes and humorous examples effectively conveys their message, making the content more accessible and enjoyable for the listeners. The speaker's vocal delivery is generally fluent, with a good balance of pace and pauses that allows the audience to follow their thoughts easily. This suggests a level of comfort with the material, which is essential for maintaining audience interest. Furthermore, the speaker's ability to convey a sense of vulnerability and shared experience through their discussion of procrastination and personal struggles adds a layer of authenticity to their presentation.\n",
       "\n",
       "## Part 2: Areas for Improvement\n",
       "\n",
       "One area where the speaker could improve is in maintaining consistent vocal energy and modulation throughout the presentation. There are moments where the speaker's voice becomes somewhat flat, which could be due to a decrease in vocal control or a shift in confidence levels. These fluctuations might make certain sections of the speech less engaging than others. Additionally, while the speaker's use of pauses is generally effective for emphasis and clarity, there are instances where the pauses might be slightly too long or too frequent, potentially disrupting the flow of the narrative. Working on smoothing out these transitions could enhance the overall delivery.\n",
       "\n",
       "## Part 3: Confidence and Fluency Assessment\n",
       "\n",
       "Based on the speaker's performance, it's evident that they possess a good level of confidence in their material, which is reflected in their generally fluent delivery and engaging storytelling. However, there are subtle hints of hesitation or decreased vocal control in certain segments, which might suggest slight dips in confidence or comfort with specific topics. The speaker's fluency is notable, with a clear and coherent presentation of ideas, indicating strong preparation and familiarity with the subject matter. Overall, I would rate the speaker's confidence level as high, with minor fluctuations that do not significantly impact the effectiveness of their presentation. Their fluency level is also high, with a well-structured narrative that is easy to follow, suggesting strong communication skills. The minor areas for improvement are primarily related to fine-tuning their vocal delivery to maintain a consistent level of engagement throughout the speech."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Markdown(tim_urban_feedback.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce736c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
