{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249b5d9a",
   "metadata": {},
   "source": [
    "# Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25780097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: numpy in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: torch in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: groq in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: load_dotenv in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (4.14.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from load_dotenv) (1.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from standard-aifc->librosa) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from standard-aifc->librosa) (0.2.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\utkarsh\\onedrive\\documents\\github\\truthsense-ml\\venv\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas librosa torch groq load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bfa84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from groq import Groq\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12433cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from load_dotenv import load_dotenv\n",
    "print(load_dotenv('.env.local'))\n",
    "\n",
    "assert os.environ.get('GROQ_API_KEY'), \"Groq API key not found in .env file, please set the key before starting this notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c16201",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Features extracted:\n",
    "\t•\tZCR\n",
    "\t•\tPitch\n",
    "\t•\tRMS\n",
    "\t•\tMFCC\n",
    "\t•\tDeltaMFCC\n",
    "\t•\tSpeakingRate\n",
    "\t•\tPauseCount\n",
    "\t•\tPauseDuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b40339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    data, sr = librosa.load(audio_path)\n",
    "\n",
    "    # 1. Zero-Crossing Rate (ZCR)\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(data))\n",
    "\n",
    "    # 2. Pitch: Mean and Std Deviation\n",
    "    pitch = librosa.yin(data, fmin=librosa.note_to_hz(\"C2\"),\n",
    "                        fmax=librosa.note_to_hz(\"C7\"), sr=sr)\n",
    "    pitch = np.nan_to_num(pitch, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    pitch_mean = np.mean(pitch)\n",
    "    pitch_std = np.std(pitch)\n",
    "    pitch_var = np.var(pitch)\n",
    "\n",
    "    # 3. Energy: RMS Mean, Std, Variance\n",
    "    rms = librosa.feature.rms(y=data)[0]\n",
    "    rms_mean = np.mean(rms)\n",
    "    rms_std = np.std(rms)\n",
    "    rms_var = np.var(rms)\n",
    "\n",
    "    # 4. MFCC and Delta MFCC Mean\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_mean = np.mean(mfcc)\n",
    "    delta_mean = np.mean(delta)\n",
    "\n",
    "    # 5. Transcription\n",
    "    client = Groq()\n",
    "    with open(audio_path, \"rb\") as file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "        file=(audio_path, file.read()),\n",
    "        model=\"distil-whisper-large-v3-en\",\n",
    "        response_format=\"verbose_json\",\n",
    "        )\n",
    "\n",
    "    transcript = transcription.text\n",
    "            \n",
    "    # 6. Speaking Rate: Words per second\n",
    "    duration_sec = librosa.get_duration(y=data, sr=sr)\n",
    "    word_count = len(transcript.split())\n",
    "    speaking_rate = word_count / duration_sec if duration_sec > 0 else 0\n",
    "\n",
    "    # 7. Long Pauses (>1s)\n",
    "    intervals = librosa.effects.split(data, top_db=30)\n",
    "    pauses = []\n",
    "    for i in range(1, len(intervals)):\n",
    "        prev_end = intervals[i-1][1]\n",
    "        cur_start = intervals[i][0]\n",
    "        silence_duration = (cur_start - prev_end) / sr\n",
    "        if silence_duration > 1.0:\n",
    "            pauses.append(silence_duration)\n",
    "    long_pause_count = len(pauses)\n",
    "    long_pause_total = sum(pauses)\n",
    "\n",
    "    return {\n",
    "        \"transcript\": transcript,\n",
    "        \"zcr\": zcr,\n",
    "        \"pitch_mean\": pitch_mean,\n",
    "        \"pitch_std\": pitch_std,\n",
    "        \"pitch_var\": pitch_var,\n",
    "        \"rms_mean\": rms_mean,\n",
    "        \"rms_std\": rms_std,\n",
    "        \"rms_var\": rms_var,\n",
    "        \"speaking_rate\": speaking_rate,\n",
    "        \"long_pause_count\": long_pause_count,\n",
    "        \"long_pause_duration\": long_pause_total,\n",
    "        \"mfcc_mean\": mfcc_mean,\n",
    "        \"delta_mean\": delta_mean\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc49174",
   "metadata": {},
   "source": [
    "# Send to GPT for feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "751d8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feedback(features):\n",
    "    prompt = f\"\"\"\n",
    "You're a communication coach. Analyze the following features of a speaker:\n",
    "\n",
    "- Transcript: {features['transcript']}\n",
    "- ZCR: {features['zcr']}\n",
    "- Mean pitch: {features['pitch_mean']}\n",
    "- Std pitch: {features['pitch_std']}\n",
    "- Pitch Variance: {features['pitch_var']}\n",
    "- RMS (mean/std/var): {features['rms_mean']}, {features['rms_std']}, {features['rms_var']}\n",
    "- Speaking rate: {features['speaking_rate']} words/sec\n",
    "- Long pauses: {features['long_pause_count']} pauses totaling {features['long_pause_duration']} sec\n",
    "- MFCC mean: {features['mfcc_mean']}\n",
    "- Delta MFCC mean: {features['delta_mean']}\n",
    "\n",
    "Based on this data, provide feedback on the user's fluency, confidence, and delivery. Do not give a lot of weightage \n",
    "to the transcript, they may use the right words to confuse you, use the audio features that you've been given to primarily detect the 3 traits\n",
    "\"\"\"\n",
    "\n",
    "    client = Groq()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_completion_tokens=32768,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211bdbf",
   "metadata": {},
   "source": [
    "# Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0365e68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\AppData\\Local\\Temp\\ipykernel_22416\\4173213159.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sr = librosa.load(audio_path)\n"
     ]
    }
   ],
   "source": [
    "# An unconfident speech\n",
    "path = \"samples/unconfident.m4a\"\n",
    "features = extract_features(path)\n",
    "feedback = generate_feedback(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcd139ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcript': \" Um, um, so, so, so, my name is Utkarsh Malaya. I'm a very, very scared student and I have, I have a fear of public speaking. So this is, this is, this is, this is very difficult for me. And, yeah, I'm just, just trying to get one model that can recognize these filler words.\",\n",
       " 'zcr': np.float64(0.0805518689798599),\n",
       " 'pitch_mean': np.float64(271.47274691287276),\n",
       " 'pitch_std': np.float64(477.2604483344195),\n",
       " 'pitch_var': np.float64(227777.53554437112),\n",
       " 'rms_mean': np.float32(0.0074115577),\n",
       " 'rms_std': np.float32(0.007082585),\n",
       " 'rms_var': np.float32(5.0163006e-05),\n",
       " 'speaking_rate': 2.075784313557683,\n",
       " 'long_pause_count': 1,\n",
       " 'long_pause_duration': np.float64(1.555736961451247),\n",
       " 'mfcc_mean': np.float32(-27.511122),\n",
       " 'delta_mean': np.float32(0.006345318)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e792308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided audio features, I'll analyze the speaker's fluency, confidence, and delivery.\n",
       "\n",
       "**Fluency:**\n",
       "The speaker's fluency appears to be affected by their nervousness. The presence of filler words (\"um\", \"so\") in the transcript, although not the primary focus, is supported by the audio features. The speaking rate of 2.075 words/sec is slightly slower than average, which may indicate hesitation or difficulty in finding the right words. The long pause of 1.555 seconds also suggests that the speaker is taking time to gather their thoughts or calm their nerves. The Mean Pitch (271.47) and Std Pitch (477.26) are relatively high, which could be a sign of tension or anxiety affecting their vocal delivery. Considering these factors, I'd rate the speaker's fluency as 6/10.\n",
       "\n",
       "**Confidence:**\n",
       "The speaker's confidence seems to be low. The high Pitch Variance (227777.54) and Std Pitch (477.26) indicate that their tone is wavering, which is often a sign of nervousness or lack of confidence. The ZCR (Zero Crossing Rate) of 0.0806 is relatively low, which may suggest a more monotone or hesitant delivery. The RMS (mean) of 0.0074 is relatively low, indicating a softer voice, which can be a sign of lack of confidence. The MFCC mean (-27.51) and Delta MFCC mean (0.0063) are within normal ranges, but the overall combination of these features suggests that the speaker is not confident in their delivery. I'd rate the speaker's confidence as 4/10.\n",
       "\n",
       "**Delivery:**\n",
       "The speaker's delivery is affected by their nervousness and lack of confidence. The slow speaking rate and long pauses contribute to a somewhat hesitant delivery. The high Pitch Variance and Std Pitch make their tone less stable, which can be distracting for the audience. However, the speaker is trying to convey their message, and their RMS (std) of 0.0071 is relatively consistent, indicating some control over their voice. The MFCC features are within normal ranges, suggesting that the speaker's pronunciation and articulation are not significantly affected. Overall, I'd rate the speaker's delivery as 5/10.\n",
       "\n",
       "To improve, the speaker could focus on relaxation techniques to reduce their nervousness, practice speaking at a slightly faster pace, and work on maintaining a more stable tone. Recording themselves and listening to the playback could help them become more aware of their filler words, pauses, and tone. With practice and experience, they can develop greater fluency, confidence, and delivery skills."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Markdown(feedback.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a8ec9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utkarsh\\AppData\\Local\\Temp\\ipykernel_22416\\4173213159.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sr = librosa.load(audio_path)\n"
     ]
    }
   ],
   "source": [
    "# A confident speech\n",
    "path = \"samples/confident.m4a\"\n",
    "features = extract_features(path)\n",
    "feedback = generate_feedback(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41201a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcript': \" Hi, my name is Adkarsh Malaya. I'm a student and right now what I'm trying to do is I'm trying to get a model and I'm trying to use it to transcribe some filler words. I am very scared. I don't know what will happen and I really really hope this works.\",\n",
       " 'zcr': np.float64(0.08035611403023599),\n",
       " 'pitch_mean': np.float64(287.1815062705668),\n",
       " 'pitch_std': np.float64(466.33901796330355),\n",
       " 'pitch_var': np.float64(217472.07967497836),\n",
       " 'rms_mean': np.float32(0.0131712835),\n",
       " 'rms_std': np.float32(0.010488089),\n",
       " 'rms_var': np.float32(0.00011000002),\n",
       " 'speaking_rate': 3.3073250933844847,\n",
       " 'long_pause_count': 0,\n",
       " 'long_pause_duration': 0,\n",
       " 'mfcc_mean': np.float32(-24.901373),\n",
       " 'delta_mean': np.float32(0.016268123)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc7ec295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided audio features, I'll analyze the speaker's fluency, confidence, and delivery.\n",
       "\n",
       "**Fluency:**\n",
       "The speaking rate of 3.3073250933844847 words/sec is slightly above average, indicating that the speaker is trying to convey their message at a moderate pace. However, the Zero Crossing Rate (ZCR) of 0.08035611403023599 is relatively low, which may suggest a more hesitant or uncertain tone. The lack of long pauses (0 pauses totaling 0 sec) is a positive indicator of fluency, as it shows the speaker is able to maintain a consistent flow. Overall, I would rate the speaker's fluency as average, with some room for improvement in terms of smoothness and naturalness.\n",
       "\n",
       "**Confidence:**\n",
       "The speaker's confidence can be inferred from their pitch and volume characteristics. The mean pitch of 287.1815062705668 is relatively high, which can be an indicator of anxiety or nervousness. The standard deviation of pitch (466.33901796330355) is quite high, suggesting significant pitch variations, which can be a sign of emotional instability. The RMS (mean, std, var) values are relatively low, indicating a soft and inconsistent volume. These audio features, combined with the speaker's explicit statement of being \"very scared\" in the transcript, suggest that the speaker is likely feeling anxious and lacking confidence.\n",
       "\n",
       "**Delivery:**\n",
       "The delivery of the speaker can be evaluated based on their prosody and articulation. The pitch variance (217472.07967497836) is high, which can make the speech sound less engaging and more monotonous. The MFCC mean (-24.9013729095459) and delta MFCC mean (0.01626812294125557) values are within normal ranges, indicating no significant issues with articulation. However, the overall delivery is likely to be perceived as nervous and uncertain due to the high pitch variability and soft volume. To improve their delivery, the speaker could focus on relaxing their tone, varying their pitch in a more controlled manner, and projecting their voice more confidently.\n",
       "\n",
       "In summary, based on the audio features, the speaker's fluency is average, their confidence is low, and their delivery is nervous and uncertain. With practice and training, the speaker can work on improving their fluency, confidence, and delivery to become a more effective and engaging communicator."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipd.Markdown(feedback.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54ec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
